{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/146790g/pytorch_advanced/blob/master/3_Training_7_training_wo_evaluation_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKjKBLLYAvla"
      },
      "source": [
        "> **Data Set** :  CT MSD Lung\n",
        "\n",
        "*   http://medicaldecathlon.com/\n",
        "\n",
        "> **Coding** **Stye**: Pytorch_TypeA\n",
        "\n",
        "> **Model**: Simple UNet\n",
        "\n",
        "> **Section**: Training\n",
        "\n",
        "> **SubSection**: continued training without evaluation , via bceloss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aPK7bsjlwQN",
        "outputId": "f7ec7689-bd7a-4c3d-d653-a3c5f8bc91a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "%pwd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvcb-3pQlylP",
        "outputId": "5784196d-aeb2-464f-8aee-e447f728ed41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imgaug==0.4.0 in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.8.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.21.6)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (0.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (7.1.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (1.3.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug==0.4.0) (4.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nibabel==3.2.1 in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from nibabel==3.2.1) (1.21.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from nibabel==3.2.1) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->nibabel==3.2.1) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install imgaug==0.4.0\n",
        "!pip install nibabel==3.2.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONj5Q7lYBsZY"
      },
      "source": [
        "### ランタイムを再実行ボタンを押す"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zCxnWoIlr5i",
        "outputId": "b402dc01-695a-45cb-92ce-394f704edfb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n",
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# パッケージのimport\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import PIL\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import torch\n",
        "import numpy as np\n",
        "import imgaug\n",
        "import imageio\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
        "\n",
        "# パッケージのimport\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import os.path as osp\n",
        "from PIL import Image\n",
        "\n",
        "import torch.utils.data as data\n",
        "\n",
        "\n",
        "# パッケージのimport\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "#import torch.utils.data as data\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import PIL\n",
        "import cv2\n",
        "\n",
        "# パッケージのimport\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import datetime\n",
        "import pytz\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import os.path as osp\n",
        "from PIL import Image\n",
        "\n",
        "import torch.utils.data as data\n",
        "\n",
        "\n",
        "# パッケージのimport\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "#import torch.utils.data as data\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxiKfixThGiZ",
        "outputId": "b337dd15-629c-46b6-8433-733eaf6cf445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.1.2\n",
            "7.1.2\n",
            "1.11.0+cu113\n",
            "2.8.2\n",
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "print(cv2.__version__)\n",
        "print(PIL.__version__)\n",
        "print(torch.__version__)\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXQIsqaBHJnm"
      },
      "source": [
        "### PyTorchの乱数シード固定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql0h5WGoHF-W"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def torch_fix_seed(seed=42):\n",
        "    # Python random\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.use_deterministic_algorithms = True\n",
        "\n",
        "torch_fix_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDk9_PeQ54HX",
        "outputId": "766822dc-a259-4e36-d70b-e4d747433b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用デバイス： cuda:0\n"
          ]
        }
      ],
      "source": [
        "# GPUが使えるかを確認\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"使用デバイス：\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaNV8PG84j7q",
        "outputId": "7af5b162-a3ef-4b06-c8fa-48176d2df8ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/DL/2 Segmentation 03 CT MSD Lung\n"
          ]
        }
      ],
      "source": [
        "root_dir = Path('/content/gdrive/My Drive/Colab Notebooks/DL/2 Segmentation 03 CT MSD Lung')\n",
        "data_dir = root_dir/Path('Preprocessed')\n",
        "dsets_dir = root_dir/Path('dsets_torch')\n",
        "models_dir = root_dir/Path('models_torch')\n",
        "cur_dir = root_dir/Path('Pytorch_TypeA_2D Unet')\n",
        "metrics_dir = cur_dir/Path('metrics')\n",
        "network_dir = cur_dir/Path('networks')\n",
        "\n",
        "##set current directory \n",
        "##root_dirにセットしないとfrom dsets.dsets import Aが作動しない。\n",
        "os.chdir(root_dir)\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lXO4ctIsNjZ",
        "outputId": "965477ff-7d68-405e-99d3-956dea039e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/DL/2 Segmentation 03 CT MSD Lung/Pytorch_TypeA_2D Unet/networks\n"
          ]
        }
      ],
      "source": [
        "print(network_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU6-toW7Dg6z"
      },
      "source": [
        "#Dataloaderからバッチデータを作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBCD6YDm68Vf"
      },
      "source": [
        "###SegmentationにおけるWeightedRandomSamplerの使い方"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imgaug\n",
        "import imageio\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import glob\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random \n",
        "\n",
        "# パッケージのimport\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "def change_img_to_label_path(path):\n",
        "  parts = list(path.parts)\n",
        "  parts[parts.index(\"data\")] = \"masks\"\n",
        "  return Path(*parts)\n",
        "\n",
        "\n",
        "def make_path_list(root,phase='train'):\n",
        "  CandidateInfoTuple = namedtuple('CandidateInfoTuple', ['anno_path','img_path'])\n",
        "  candidateInfo_list=list()\n",
        "  for img_path in root.glob('{}/*/data/*.npy'.format(phase)):\n",
        "    anno_path=change_img_to_label_path(img_path)\n",
        "  \n",
        "    candidateInfo_list.append(\n",
        "        CandidateInfoTuple(\n",
        "            anno_path,\n",
        "            img_path))\n",
        "  \n",
        "  \n",
        "  return candidateInfo_list\n",
        "\n",
        "\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Affine(scale=(0.85, 1.15), # Zoom in or out\n",
        "               rotate=(-45, 45)),  # Rotate up to 45 degrees\n",
        "    iaa.ElasticTransformation()  # Random Elastic Deformations\n",
        "                ])\n",
        "\n",
        "#segmap = ia.SegmentationMapsOnImage(np.zeros((3, 3, 1), dtype=np.int32), shape=(3, 3, 3), nb_classes=1+5)\n",
        "#segmap = ia.SegmentationMapsOnImage(np.zeros((3, 3, 1), dtype=np.int32), shape=(3, 3, 3))\n",
        "\n",
        "#augment_params=seq\n",
        "\n",
        "\n",
        "def ImageTransform(img,mask):\n",
        "  random_seed = torch.randint(0, 1000000, (1,)).item()\n",
        "  imgaug.seed(random_seed)\n",
        "\n",
        "  mask = SegmentationMapsOnImage(mask, mask.shape)\n",
        "  img_aug, mask_aug = seq(image=img, segmentation_maps=mask)\n",
        "  mask_aug = mask_aug.get_arr()\n",
        "  return img_aug, mask_aug\n",
        "\n",
        "        \n",
        "#####################################################################\n",
        "#  \n",
        "#   (3) MakeDataset Class\n",
        "#\n",
        "#####################################################################\n",
        "        \n",
        "\n",
        "import random\n",
        "\n",
        "        \n",
        "\n",
        "# with ImageTransform\n",
        "\n",
        "class MakeDataset(Dataset):\n",
        "\n",
        "    def __init__(self,file_list,transform=None,phase='train'):\n",
        "        self.file_list = file_list[phase]\n",
        "        self.phase = phase\n",
        "        self.transform = transform\n",
        "\n",
        "        #random.shuffle(self.file_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self,ndx):\n",
        "\n",
        "        # 1. 画像読み込み\n",
        "        candidateInfo_tup = self.file_list[ndx]\n",
        "        img = np.load(candidateInfo_tup.img_path).astype(np.float32)\n",
        "\n",
        "        # 2. アノテーション画像読み込み\n",
        "        anno_class_img = np.load(candidateInfo_tup.anno_path).astype(np.int8)\n",
        "        \n",
        "        if self.transform:\n",
        "          img, anno_class_img = self.transform(img, anno_class_img)\n",
        "          #print('do transform')\n",
        "          \n",
        "        #img, anno_class_img = np.expand_dims(img, 0), np.expand_dims(anno_class_img, 0)\n",
        "        img= np.expand_dims(img, 0)\n",
        "\n",
        "        return img.astype(np.float32), anno_class_img.astype(np.int8)"
      ],
      "metadata": {
        "id": "rcDXv0QNWcqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG3x_H2w4lPP",
        "outputId": "96214fdf-dcc4-4846-fe41-8e7f2fdb4442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17506\n",
            "1492\n",
            "There are 17506 train images and 1492 val images\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from dsets_torch.dsets import ImageTransform\n",
        "import random\n",
        "from dsets_torch.dsets import MakeDataset\n",
        "from dsets_torch.dsets import make_path_list\n",
        "import torch.utils.data as data\n",
        "\n",
        "\n",
        "train_list = make_path_list(data_dir,phase=\"train\")\n",
        "val_list = make_path_list(data_dir,phase=\"val\")\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(val_list))\n",
        "\n",
        "file_list={'train':train_list,'val':val_list}\n",
        "\n",
        "train_dataset = MakeDataset(file_list=file_list,transform=ImageTransform,phase='train')\n",
        "val_dataset = MakeDataset(file_list=file_list,phase='val')\n",
        "\n",
        "print(f\"There are {len(train_dataset)} train images and {len(val_dataset)} val images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyiI2tYs-2Qt"
      },
      "source": [
        "###weight_listの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77T7MYe9-467",
        "outputId": "26ade1a1-2f33-4697-f1eb-58b816ed7b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 8.094025974025975, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8.094025974025975, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8.094025974025975, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "17506\n"
          ]
        }
      ],
      "source": [
        "with open(os.path.join(dsets_dir,'weight_list.pickle'),'rb') as f:\n",
        "  weight_list=pickle.load(f)\n",
        "\n",
        "print(weight_list[100:500])\n",
        "print(len(weight_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa79pv0O7Jjn"
      },
      "outputs": [],
      "source": [
        "\n",
        "batch_size = 20\n",
        "num_workers = 1\n",
        "\n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(weight_list, len(weight_list))\n",
        "\n",
        "train_dl = data.DataLoader(train_dataset, batch_size=batch_size,num_workers=num_workers, sampler=sampler)\n",
        "val_dl = data.DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers,shuffle=False)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsIfDfXl8ZWc",
        "outputId": "3c97a9ee-6d2a-4795-f985-f7fc7501593b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2188\n",
            "186\n"
          ]
        }
      ],
      "source": [
        "print(17506//8)\n",
        "print(1492//8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKOXsOCd7woE",
        "outputId": "0edc7f27-ef0d-48c1-d557-a6ab6eaa9654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "876\n",
            "75\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dl))\n",
        "print(len(val_dl))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verify_sampler = next(iter(train_dl)) "
      ],
      "metadata": {
        "id": "_8af_eIW0tQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label_t = verify_sampler\n"
      ],
      "metadata": {
        "id": "BxNmW4ZP1GaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=label_t.numpy()\n",
        "\n",
        "total=[]\n",
        "for i in range(len(label_t)):\n",
        "  num=np.any(data[i])\n",
        "  total.append(num)\n",
        "\n",
        "print(sum(total)/len(label_t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-nYW67U0xra",
        "outputId": "77c327ce-06d2-406f-ccc4-5c386fc5778f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnG-BM8jlr5j"
      },
      "source": [
        "##Unetのネットワーク構造\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGRK3D5Dw-yx"
      },
      "outputs": [],
      "source": [
        "# モデルの定義\n",
        "import torch\n",
        "from torch.nn import init\n",
        "import functools\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import os\n",
        "import pickle \n",
        "\n",
        "#####################################################################\n",
        "#  \n",
        "#   (1) Network\n",
        "#\n",
        "#####################################################################\n",
        "\n",
        "class DoubleConv(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Helper Class which implements the intermediate Convolutions\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.step = torch.nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "                                        torch.nn.ReLU(),\n",
        "                                        torch.nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "                                        torch.nn.ReLU())\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.step(X)\n",
        "\n",
        "\n",
        "class UNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.layer1 = DoubleConv(1, 64)\n",
        "        self.layer2 = DoubleConv(64, 128)\n",
        "        self.layer3 = DoubleConv(128, 256)\n",
        "        self.layer4 = DoubleConv(256, 512)\n",
        "        \n",
        "        self.layer5 = DoubleConv(512+256, 256)\n",
        "        self.layer6 = DoubleConv(256+128, 128)\n",
        "        self.layer7 = DoubleConv(128+64, 64)\n",
        "        self.layer8 = torch.nn.Conv2d(64, 1, 1)\n",
        "        self.layer9 = torch.nn.Sigmoid()\n",
        "        \n",
        "        self.maxpool = torch.nn.MaxPool2d(2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x1 = self.layer1(x)\n",
        "        x1m = self.maxpool(x1)\n",
        "        \n",
        "        x2 = self.layer2(x1m)\n",
        "        x2m = self.maxpool(x2)\n",
        "        \n",
        "        x3 = self.layer3(x2m)\n",
        "        x3m = self.maxpool(x3)\n",
        "        \n",
        "        x4 = self.layer4(x3m)\n",
        "        \n",
        "        x5_1 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x4)\n",
        "        x5_2 = torch.cat([x5_1, x3], dim=1)\n",
        "        x5 = self.layer5(x5_2)\n",
        "        \n",
        "        x6 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x5)\n",
        "        x6 = torch.cat([x6, x2], dim=1)\n",
        "        x6 = self.layer6(x6)\n",
        "        \n",
        "        x7 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x6)\n",
        "        x7 = torch.cat([x7, x1], dim=1)\n",
        "        x7 = self.layer7(x7)\n",
        "        \n",
        "        x8 = self.layer8(x7)\n",
        "        output = self.layer9(x8)\n",
        "        return output       \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet()"
      ],
      "metadata": {
        "id": "oKbhic36PdfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAEiyXcaPYoW"
      },
      "source": [
        "#学習済みモデルおよび評価指標の保存用の関数の作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsldyDyEPf-5"
      },
      "source": [
        "#train_model関数の作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuJjlMKCTZit",
        "outputId": "2dd9e207-b9c8-46b7-ddd5-f0b4a03cfcff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGVgkv7BigNu"
      },
      "outputs": [],
      "source": [
        "def save_model(network, epoch_ndx):\n",
        "  save_filename = 'model_%s.pth' % (epoch_ndx)\n",
        "  save_path = os.path.join(network_dir, save_filename)\n",
        "  torch.save(network.cpu().state_dict(), save_path)\n",
        "\n",
        "\n",
        "def train_model(model,dataloaders_dict,epoch_start,epoch_end,lr):\n",
        "\n",
        "  now = datetime.datetime.now(pytz.timezone('Asia/Tokyo'))\n",
        "  print('start time:',now)\n",
        "\n",
        "  t_epoch_start = time.time()\n",
        "  #optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "  #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
        "\n",
        "  num_epochs=epoch_end-epoch_start+1\n",
        "\n",
        "  for epoch_ndx in range(epoch_start,epoch_end+1):\n",
        "   \n",
        "    print('-----------------------------------------------------------------------------------------')\n",
        "    now = datetime.datetime.now(pytz.timezone('Asia/Tokyo'))\n",
        "    print('Epoch:{} 【From Epoch {}:To Epoch {}】:Now {}'.format(epoch_ndx,epoch_start,epoch_end,now))\n",
        "    print('-----------------------------------------------------------------------------------------')\n",
        "\n",
        "    model.to(device)\n",
        "    for phase in ['train', 'val']:\n",
        "\n",
        "      t_epoch_start = time.time()\n",
        "      iteration = 1\n",
        "\n",
        "      if phase == 'train':\n",
        "        model.train()  # モデルを訓練モードに\n",
        "        #print('-------------')\n",
        "        print('（train）')\n",
        "        #print('-------------')\n",
        "      else:\n",
        "        model.eval()   # モデルを検証モードに\n",
        "        #print('-------------')\n",
        "        print('（val）')\n",
        "        #print('-------------')\n",
        "      \n",
        "      epoch_loss = 0.0  # epochの損失和\n",
        "\n",
        "      # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
        "      if (epoch_ndx == 0) and (phase == 'train'):\n",
        "        continue\n",
        "\n",
        "      #for batch_ndx, batch_tup in enumerate(tqdm(dataloaders_dict[phase])):\n",
        "      for batch_ndx, batch_tup in enumerate(dataloaders_dict[phase]):\n",
        "\n",
        "        t_iter_start = time.time()\n",
        "        input_t, label_t = batch_tup\n",
        "        input_g=input_t.to(device)\n",
        "        label_g=label_t.to(device)\n",
        "        del input_t,label_t,batch_tup\n",
        "\n",
        "        # optimizerを初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "      # 順伝搬（forward）計算\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "        \n",
        "          outputs = model(input_g)\n",
        "          loss_g = F.binary_cross_entropy_with_logits(outputs.view(-1).float(), label_g.view(-1).float())\n",
        "          #loss_g = torch.nn.BCEWithLogitsLoss(outputs.view(-1).float(), label_g.view(-1).float())\n",
        "          epoch_loss += loss_g.item() * input_g.size(0) \n",
        "\n",
        "          # 訓練時はバックプロパゲーション\n",
        "          if phase == 'train':\n",
        "            loss_g.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "      #phaseごとのlossとaccuracy\n",
        "      t_epoch_finish = time.time()\n",
        "      #print('---------------------------------------------------------------------------------------')\n",
        "      print('Duration: {:.4f} sec. '.format(t_epoch_finish - t_epoch_start))\n",
        "      #print('---------------------------------------------------------------------------------------')\n",
        "      epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "      print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
        "\n",
        "    #epochごとに周期的にモデルを保存\n",
        "    if (epoch_ndx % save_freq ==0) & (epoch_ndx>0):\n",
        "      print('saving the model at the end of epoch %d' % epoch_ndx)\n",
        "      save_model(model,epoch_ndx)\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh8X9lYcQh4c"
      },
      "source": [
        "###①初回学習の実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsMIdCJMTbSy"
      },
      "source": [
        "RuntimeWarning: Mean of empty sliceが出たときには、batch_sizeを変える"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybkQQECkQlLB",
        "outputId": "6aa0f851-7ebd-46d6-d01d-a4dbdfda683e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start time: 2022-06-09 11:16:51.817831+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:4 【From Epoch 4:To Epoch 6】:Now 2022-06-09 11:16:51.818408+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 1048.9961 sec. \n",
            "train Loss: 0.7019\n",
            "（val）\n",
            "Duration: 20.5216 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:5 【From Epoch 4:To Epoch 6】:Now 2022-06-09 11:34:41.351793+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1975 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5283 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:6 【From Epoch 4:To Epoch 6】:Now 2022-06-09 11:47:25.083403+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1892 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5102 sec. \n",
            "val Loss: 0.6931\n",
            "saving the model at the end of epoch 6\n"
          ]
        }
      ],
      "source": [
        "# 学習・検証を実行する\n",
        "epoch_start=4\n",
        "save_freq=3\n",
        "epoch_end=save_freq*2\n",
        "lr = (1e-04)*0.5\n",
        "\n",
        "train_model(model,dataloaders_dict,epoch_start,epoch_end,lr)    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_ndx=6\n",
        "\n",
        "from models_torch.models import UNet\n",
        "model = UNet()\n",
        "\n",
        "load_filename = 'model_%s.pth' % (epoch_ndx)\n",
        "load_path = os.path.join(network_dir, load_filename)\n",
        "\n",
        "# PyTorchのネットワークパラメータのロード\n",
        "model.load_state_dict(torch.load(load_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iQkmdEXfUzE",
        "outputId": "4c8e9ce3-b0a0-4b3d-bc4f-e54460ad973f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習・検証を実行する\n",
        "epoch_start=7\n",
        "save_freq=5\n",
        "epoch_end=save_freq*20\n",
        "lr = (1e-04)*0.5\n",
        "\n",
        "train_model(model,dataloaders_dict,epoch_start,epoch_end,lr)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BVaCKnxxfbf5",
        "outputId": "d998655d-c7c9-414a-f523-a63ed839268d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start time: 2022-06-09 12:24:33.223822+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:7 【From Epoch 7:To Epoch 100】:Now 2022-06-09 12:24:33.224923+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 844.0199 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5058 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:8 【From Epoch 7:To Epoch 100】:Now 2022-06-09 12:38:57.766087+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 772.5893 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5303 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:9 【From Epoch 7:To Epoch 100】:Now 2022-06-09 12:52:10.890460+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.7391 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5273 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:10 【From Epoch 7:To Epoch 100】:Now 2022-06-09 13:04:55.162579+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 744.0379 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5208 sec. \n",
            "val Loss: 0.6931\n",
            "saving the model at the end of epoch 10\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:11 【From Epoch 7:To Epoch 100】:Now 2022-06-09 13:17:40.480260+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1813 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5223 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:12 【From Epoch 7:To Epoch 100】:Now 2022-06-09 13:30:24.206529+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1853 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5125 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:13 【From Epoch 7:To Epoch 100】:Now 2022-06-09 13:43:07.909364+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1898 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5400 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:14 【From Epoch 7:To Epoch 100】:Now 2022-06-09 13:55:51.644742+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1784 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5244 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:15 【From Epoch 7:To Epoch 100】:Now 2022-06-09 14:08:35.351770+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1035 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5122 sec. \n",
            "val Loss: 0.6931\n",
            "saving the model at the end of epoch 15\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:16 【From Epoch 7:To Epoch 100】:Now 2022-06-09 14:21:19.088337+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1078 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5146 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:17 【From Epoch 7:To Epoch 100】:Now 2022-06-09 14:34:02.729690+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.0694 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.4979 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:18 【From Epoch 7:To Epoch 100】:Now 2022-06-09 14:46:46.302554+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1224 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5104 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:19 【From Epoch 7:To Epoch 100】:Now 2022-06-09 14:59:29.941364+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1805 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5048 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:20 【From Epoch 7:To Epoch 100】:Now 2022-06-09 15:12:13.634958+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1945 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5259 sec. \n",
            "val Loss: 0.6931\n",
            "saving the model at the end of epoch 20\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:21 【From Epoch 7:To Epoch 100】:Now 2022-06-09 15:24:58.197858+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2157 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5146 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:22 【From Epoch 7:To Epoch 100】:Now 2022-06-09 15:37:41.952806+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2447 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5523 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:23 【From Epoch 7:To Epoch 100】:Now 2022-06-09 15:50:25.754491+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2675 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5180 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:24 【From Epoch 7:To Epoch 100】:Now 2022-06-09 16:03:09.544349+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2265 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5179 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:25 【From Epoch 7:To Epoch 100】:Now 2022-06-09 16:15:53.296573+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2053 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5315 sec. \n",
            "val Loss: 0.6931\n",
            "saving the model at the end of epoch 25\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:26 【From Epoch 7:To Epoch 100】:Now 2022-06-09 16:28:38.213957+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2197 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5142 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:27 【From Epoch 7:To Epoch 100】:Now 2022-06-09 16:41:21.969372+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2457 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5366 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:28 【From Epoch 7:To Epoch 100】:Now 2022-06-09 16:54:05.755918+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.1947 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5276 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:29 【From Epoch 7:To Epoch 100】:Now 2022-06-09 17:06:49.483086+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2368 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5364 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:30 【From Epoch 7:To Epoch 100】:Now 2022-06-09 17:19:33.260807+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2360 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5232 sec. \n",
            "val Loss: 0.6931\n",
            "saving the model at the end of epoch 30\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:31 【From Epoch 7:To Epoch 100】:Now 2022-06-09 17:32:18.222289+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2427 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5208 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:32 【From Epoch 7:To Epoch 100】:Now 2022-06-09 17:45:02.011781+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2375 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5195 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:33 【From Epoch 7:To Epoch 100】:Now 2022-06-09 17:57:45.773045+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2890 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5435 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:34 【From Epoch 7:To Epoch 100】:Now 2022-06-09 18:10:29.609626+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2681 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5334 sec. \n",
            "val Loss: 0.6931\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:35 【From Epoch 7:To Epoch 100】:Now 2022-06-09 18:23:13.419011+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n",
            "Duration: 743.2937 sec. \n",
            "train Loss: 0.6931\n",
            "（val）\n",
            "Duration: 20.5219 sec. \n",
            "val Loss: 0.6931\n",
            "saving the model at the end of epoch 35\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch:36 【From Epoch 7:To Epoch 100】:Now 2022-06-09 18:35:58.288031+09:00\n",
            "-----------------------------------------------------------------------------------------\n",
            "（train）\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-3517504cbfda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1e-04\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-f36586a5a757>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders_dict, epoch_start, epoch_end, lr)\u001b[0m\n\u001b[1;32m     66\u001b[0m           \u001b[0mloss_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m           \u001b[0;31m#loss_g = torch.nn.BCEWithLogitsLoss(outputs.view(-1).float(), label_g.view(-1).float())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m           \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0;31m# 訓練時はバックプロパゲーション\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceScore(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    class to compute the Dice Loss\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, mask):\n",
        "                \n",
        "        #flatten label and prediction tensors\n",
        "        pred = torch.flatten(pred)\n",
        "        mask = torch.flatten(mask)\n",
        "        \n",
        "        counter = (pred * mask).sum()  # Counter       \n",
        "        denum = pred.sum() + mask.sum()  # denominator\n",
        "        dice = (2*counter)/denum\n",
        "        \n",
        "        return dice\n"
      ],
      "metadata": {
        "id": "96LlVlCI76gw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "labels = []\n",
        "\n",
        "for slice, label in tqdm(val_dataset):\n",
        "    slice = torch.tensor(slice).float().to(device).unsqueeze(0)\n",
        "    model.to(device)\n",
        "    with torch.no_grad():\n",
        "        pred = model(slice)\n",
        "    preds.append(pred.cpu().numpy())\n",
        "    labels.append(label)\n",
        "    \n",
        "preds = np.array(preds)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "squliJyp7wC7",
        "outputId": "f28e7bb5-c50b-4498-8e42-b6a193822aeb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1492/1492 [00:37<00:00, 40.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dice_score = DiceScore()(torch.from_numpy(preds), torch.from_numpy(labels).unsqueeze(0).float())\n",
        "print(f\"The Val Dice Score is: {dice_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV0DZoFH74wA",
        "outputId": "0fbb7dcd-af48-4313-f1a3-d03ef783fc94"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Val Dice Score is: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp5W9VX-lr5n"
      },
      "source": [
        "#END"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "3_Training_7_training_wo_evaluation_01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}